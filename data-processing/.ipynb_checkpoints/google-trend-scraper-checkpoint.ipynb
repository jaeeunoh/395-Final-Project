{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import copy\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "import sys\n",
    "import json\n",
    "import urllib\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "\n",
    "from StringIO import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: Books & Literature\n",
      "\n",
      "Week,panda: (United States)\n",
      "2015-01-11,40\n",
      "2015-01-18,30\n",
      "2015-01-25,46\n",
      "2015-02-01,33\n",
      "2015-02-08,34\n",
      "2015-02-15,49\n",
      "2015-02-22,36\n",
      "2015-03-01,34\n",
      "2015-03-08,37\n",
      "2015-03-15,42\n",
      "2015-03-22,44\n",
      "2015-03-29,34\n",
      "2015-04-05,50\n",
      "2015-04-12,36\n",
      "2015-04-19,40\n",
      "2015-04-26,31\n",
      "2015-05-03,43\n",
      "2015-05-10,36\n",
      "2015-05-17,30\n",
      "2015-05-24,26\n",
      "2015-05-31,30\n",
      "2015-06-07,31\n",
      "2015-06-14,43\n",
      "2015-06-21,31\n",
      "2015-06-28,25\n",
      "2015-07-05,24\n",
      "2015-07-12,28\n",
      "2015-07-19,25\n",
      "2015-07-26,30\n",
      "2015-08-02,32\n",
      "2015-08-09,27\n",
      "2015-08-16,26\n",
      "2015-08-23,40\n",
      "2015-08-30,26\n",
      "2015-09-06,34\n",
      "2015-09-13,33\n",
      "2015-09-20,42\n",
      "2015-09-27,38\n",
      "2015-10-04,28\n",
      "2015-10-11,53\n",
      "2015-10-18,30\n",
      "2015-10-25,33\n",
      "2015-11-01,41\n",
      "2015-11-08,44\n",
      "2015-11-15,41\n",
      "2015-11-22,36\n",
      "2015-11-29,36\n",
      "2015-12-06,42\n",
      "2015-12-13,48\n",
      "2015-12-20,49\n",
      "2015-12-27,41\n",
      "2016-01-03,35\n",
      "2016-01-10,46\n",
      "2016-01-17,46\n",
      "2016-01-24,79\n",
      "2016-01-31,100\n",
      "2016-02-07,65\n",
      "2016-02-14,70\n",
      "2016-02-21,54\n",
      "2016-02-28,58\n",
      "2016-03-06,65\n",
      "2016-03-13,59\n",
      "2016-03-20,57\n",
      "2016-03-27,64\n",
      "2016-04-03,70\n",
      "2016-04-10,74\n",
      "2016-04-17,87\n",
      "2016-04-24,82\n",
      "2016-05-01,97\n",
      "2016-05-08,98\n",
      "2016-05-15,98\n",
      "2016-05-22,81\n",
      "2016-05-29,78\n",
      "2016-06-05,68\n",
      "2016-06-12,66\n",
      "2016-06-19,48\n",
      "2016-06-26,49\n",
      "2016-07-03,40\n",
      "2016-07-10,58\n",
      "2016-07-17,45\n",
      "2016-07-24,43\n",
      "2016-07-31,39\n",
      "2016-08-07,36\n",
      "2016-08-14,40\n",
      "2016-08-21,39\n",
      "2016-08-28,35\n",
      "2016-09-04,62\n",
      "2016-09-11,36\n",
      "2016-09-18,50\n",
      "2016-09-25,43\n",
      "2016-10-02,48\n",
      "2016-10-09,52\n",
      "2016-10-16,35\n",
      "2016-10-23,47\n",
      "2016-10-30,46\n",
      "2016-11-06,42\n",
      "2016-11-13,47\n",
      "2016-11-20,47\n",
      "2016-11-27,39\n",
      "2016-12-04,39\n",
      "2016-12-11,42\n",
      "2016-12-18,61\n",
      "2016-12-25,33\n",
      "2017-01-01,45\n",
      "2017-01-08,48\n",
      "\n",
      "[u'2015-01-11,40']\n",
      "           date volume   term\n",
      "0    2015-01-11     40  panda\n",
      "1    2015-01-18     30  panda\n",
      "2    2015-01-25     46  panda\n",
      "3    2015-02-01     33  panda\n",
      "4    2015-02-08     34  panda\n",
      "5    2015-02-15     49  panda\n",
      "6    2015-02-22     36  panda\n",
      "7    2015-03-01     34  panda\n",
      "8    2015-03-08     37  panda\n",
      "9    2015-03-15     42  panda\n",
      "10   2015-03-22     44  panda\n",
      "11   2015-03-29     34  panda\n",
      "12   2015-04-05     50  panda\n",
      "13   2015-04-12     36  panda\n",
      "14   2015-04-19     40  panda\n",
      "15   2015-04-26     31  panda\n",
      "16   2015-05-03     43  panda\n",
      "17   2015-05-10     36  panda\n",
      "18   2015-05-17     30  panda\n",
      "19   2015-05-24     26  panda\n",
      "20   2015-05-31     30  panda\n",
      "21   2015-06-07     31  panda\n",
      "22   2015-06-14     43  panda\n",
      "23   2015-06-21     31  panda\n",
      "24   2015-06-28     25  panda\n",
      "25   2015-07-05     24  panda\n",
      "26   2015-07-12     28  panda\n",
      "27   2015-07-19     25  panda\n",
      "28   2015-07-26     30  panda\n",
      "29   2015-08-02     32  panda\n",
      "..          ...    ...    ...\n",
      "75   2016-06-19     48  panda\n",
      "76   2016-06-26     49  panda\n",
      "77   2016-07-03     40  panda\n",
      "78   2016-07-10     58  panda\n",
      "79   2016-07-17     45  panda\n",
      "80   2016-07-24     43  panda\n",
      "81   2016-07-31     39  panda\n",
      "82   2016-08-07     36  panda\n",
      "83   2016-08-14     40  panda\n",
      "84   2016-08-21     39  panda\n",
      "85   2016-08-28     35  panda\n",
      "86   2016-09-04     62  panda\n",
      "87   2016-09-11     36  panda\n",
      "88   2016-09-18     50  panda\n",
      "89   2016-09-25     43  panda\n",
      "90   2016-10-02     48  panda\n",
      "91   2016-10-09     52  panda\n",
      "92   2016-10-16     35  panda\n",
      "93   2016-10-23     47  panda\n",
      "94   2016-10-30     46  panda\n",
      "95   2016-11-06     42  panda\n",
      "96   2016-11-13     47  panda\n",
      "97   2016-11-20     47  panda\n",
      "98   2016-11-27     39  panda\n",
      "99   2016-12-04     39  panda\n",
      "100  2016-12-11     42  panda\n",
      "101  2016-12-18     61  panda\n",
      "102  2016-12-25     33  panda\n",
      "103  2017-01-01     45  panda\n",
      "104  2017-01-08     48  panda\n",
      "\n",
      "[105 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "### Test\n",
    "def get_token(response_text):\n",
    "    try:\n",
    "        return response_text.split('token\":\"')[1].split('\",\"')[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_csv_request(response_text):\n",
    "    try:\n",
    "        return response_text.split('\"widgets\":')[1].split(',\"lineAnno')[0].split('\"request\":')[1]       \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "#print(requests.get(\"https://trends.google.com/trends/explore?date=2017-03-26%202017-04-26&q=fashion%20week\").text.encode('utf8'))\n",
    "time_formatted = '2015-01-06' + '+' + '2017-01-09'\n",
    "req = {\"comparisonItem\":[{\"keyword\":'panda', \"geo\":'US', \"time\": time_formatted}],\"category\": 22, \"property\":\"\"}\n",
    "hl = \"en-GB\"\n",
    "tz = \"-120\"\n",
    "#print(json.dumps(req).replace(' ','').replace('+',' '))\n",
    "explore_URL = 'https://trends.google.com/trends/api/explore?hl={0}&tz={1}&req={2}'.format(hl,tz,json.dumps(req).replace(' ','').replace('+',' '))\n",
    "#print explore_URL\n",
    "requests.get(explore_URL).text.encode('utf8')\n",
    "response_text = requests.get(explore_URL).text\n",
    "#print(response_text)\n",
    "request = get_csv_request(response_text)\n",
    "token = get_token(response_text)\n",
    "#print(response_text)\n",
    "\n",
    "csv = requests.get('https://www.google.com/trends/api/widgetdata/multiline/csv?req={0}&token={1}&tz=-120'.format(request,token))\n",
    "print(csv.text)\n",
    "print(csv.text.split('\\n')[3:4])\n",
    "text = csv.text.encode('utf8').split('\\n')\n",
    "a = text[3:len(text)-1]\n",
    "df = pd.DataFrame(columns = [\"Date\",\"Volume\"])\n",
    "#for line in a:\n",
    "#    s = line.split(',')\n",
    "#    df = df.append([s[0],'panda',s[1]])\n",
    "\n",
    "def spl (str):\n",
    "    return str.split(',')\n",
    "\n",
    "df = pd.DataFrame((map((lambda x: x.split(',')),a)))\n",
    "df['term'] = 'panda'\n",
    "df.columns = ['date', 'volume','term']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(bucket_start_date,bucket_end_date, keyword):\n",
    "    bucket_start_date_printed = datetime.strftime(bucket_start_date, '%Y-%m-%d')\n",
    "    bucket_end_date_printed = datetime.strftime(bucket_end_date, '%Y-%m-%d')\n",
    "    time_formatted = bucket_start_date_printed + '+' + bucket_end_date_printed\n",
    "\n",
    "    req = {\"comparisonItem\":[{\"keyword\":keyword, \"geo\":geo, \"time\": time_formatted}], \"category\":category,\"property\":\"\"}\n",
    "    hl = \"en-GB\"\n",
    "    tz = \"-120\"\n",
    "\n",
    "    explore_URL = 'https://trends.google.com/trends/api/explore?hl={0}&tz={1}&req={2}'.format(hl,tz,json.dumps(req).replace(' ','').replace('+',' '))\n",
    "    print explore_URL\n",
    "    print requests.get(explore_URL).text.encode('utf8')\n",
    "    return requests.get(explore_URL).text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_csv(response_text):\n",
    "    request = get_csv_request(response_text)\n",
    "    token = get_token(response_text)\n",
    "\n",
    "    csv = requests.get('https://www.google.com/trends/api/widgetdata/multiline/csv?req={0}&token={1}&tz=-120'.format(request,token))\n",
    "    return csv.text.encode('utf8')\n",
    "\n",
    "def parse_csv(csv_contents):\n",
    "    lines = csv_contents.split('\\n')\n",
    "    df = pd.DataFrame(columns = ['date','value'])\n",
    "    dates = []\n",
    "    values = []\n",
    "    # Delete top 3 lines\n",
    "    for line in lines[3:]:\n",
    "        try:\n",
    "            dates.append(line.split(',')[0].replace(' ',''))\n",
    "            values.append(line.split(',')[1].replace(' ',''))\n",
    "        except:\n",
    "            pass\n",
    "    df['date'] = dates\n",
    "    df['value'] = values\n",
    "    print df.head()\n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyentrang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:105: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(147, 2)\n"
     ]
    }
   ],
   "source": [
    "### Main\n",
    "\n",
    "def get_interest_over_time (start_date, end_date, kw_list): \n",
    "    geo = 'US'\n",
    "    category = 22\n",
    "    final_frame = pd.DataFrame()\n",
    "    for keyword in kw_list:\n",
    "        keywords = '+'.join(keyword)\n",
    "        daily_frames = get_daily_frames(start_date, end_date, keywords)\n",
    "        weekly_frame = get_weekly_frame(start_date, end_date, keywords)\n",
    "        temp = stitch_frames(keyword, daily_frames, weekly_frame)\n",
    "        final_frame = pd.concat([final_frame, temp.reset_index(drop = True)], axis = 1)\n",
    "        \n",
    "    return final_frame\n",
    "kw_list = ['a-line', 'fashion']\n",
    "\n",
    "out = get_interest_over_time(\"2015-05-05\", \"2016-07-05\", kw_list)\n",
    "print out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date volumne\n",
      "0    2015-05-05       0\n",
      "1    2015-05-06       0\n",
      "2    2015-05-07       0\n",
      "3    2015-05-08       0\n",
      "4    2015-05-09       0\n",
      "5    2015-05-10       0\n",
      "6    2015-05-11       0\n",
      "7    2015-05-12       0\n",
      "8    2015-05-13       0\n",
      "9    2015-05-14       0\n",
      "10   2015-05-15       0\n",
      "11   2015-05-16       0\n",
      "12   2015-05-17       0\n",
      "13   2015-05-18       0\n",
      "14   2015-05-19       0\n",
      "15   2015-05-20       0\n",
      "16   2015-05-21       0\n",
      "17   2015-05-22       0\n",
      "18   2015-05-23       0\n",
      "19   2015-05-24       0\n",
      "20   2015-05-25       0\n",
      "21   2015-05-26       0\n",
      "22   2015-05-27       0\n",
      "23   2015-05-28       0\n",
      "24   2015-05-29       0\n",
      "25   2015-05-30       0\n",
      "26   2015-05-31       0\n",
      "27   2015-06-01       0\n",
      "28   2015-06-02       0\n",
      "29   2015-06-03       0\n",
      "..          ...     ...\n",
      "152  2015-10-04       0\n",
      "153  2015-10-05       0\n",
      "154  2015-10-06       0\n",
      "155  2015-10-07       0\n",
      "156  2015-10-08       0\n",
      "157  2015-10-09       0\n",
      "158  2015-10-10       0\n",
      "159  2015-10-11       0\n",
      "160  2015-10-12       0\n",
      "161  2015-10-13       0\n",
      "162  2015-10-14       0\n",
      "163  2015-10-15       0\n",
      "164  2015-10-16       0\n",
      "165  2015-10-17       0\n",
      "166  2015-10-18       0\n",
      "167  2015-10-19       0\n",
      "168  2015-10-20       0\n",
      "169  2015-10-21       0\n",
      "170  2015-10-22       0\n",
      "171  2015-10-23     100\n",
      "172  2015-10-24       0\n",
      "173  2015-10-25       0\n",
      "174  2015-10-26       0\n",
      "175  2015-10-27       0\n",
      "176  2015-10-28       0\n",
      "177  2015-10-29       0\n",
      "178  2015-10-30       0\n",
      "179  2015-10-31       0\n",
      "180  2015-11-01       0\n",
      "181  2015-11-02       0\n",
      "\n",
      "[182 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nguyentrang/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:105: FutureWarning: sort(....) is deprecated, use sort_index(.....)\n"
     ]
    }
   ],
   "source": [
    "start_date = \"2015-05-05\"\n",
    "end_date = \"2016-07-05\"\n",
    "keyword = \"a-line\"\n",
    "geo = 'US'\n",
    "category = 22\n",
    "keywords = '+'.join(keyword)\n",
    "daily_frames = get_daily_frames(start_date, end_date, keywords)\n",
    "weekly_frame = get_weekly_frame(start_date, end_date, keywords)\n",
    "final_frame = stitch_frames(keywords, daily_frames, weekly_frame)\n",
    "print daily_frames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date volumne\n",
      "0   2016-05-01       0\n",
      "1   2016-05-02       0\n",
      "2   2016-05-03       0\n",
      "3   2016-05-04       0\n",
      "4   2016-05-05       0\n",
      "5   2016-05-06       0\n",
      "6   2016-05-07       0\n",
      "7   2016-05-08       0\n",
      "8   2016-05-09       0\n",
      "9   2016-05-10       0\n",
      "10  2016-05-11       0\n",
      "11  2016-05-12       0\n",
      "12  2016-05-13       0\n",
      "13  2016-05-14       0\n",
      "14  2016-05-15       0\n",
      "15  2016-05-16       0\n",
      "16  2016-05-17       0\n",
      "17  2016-05-18       0\n",
      "18  2016-05-19       0\n",
      "19  2016-05-20       0\n",
      "20  2016-05-21       0\n",
      "21  2016-05-22       0\n",
      "22  2016-05-23       0\n",
      "23  2016-05-24       0\n",
      "24  2016-05-25       0\n",
      "25  2016-05-26       0\n",
      "26  2016-05-27       0\n",
      "27  2016-05-28       0\n",
      "28  2016-05-29       0\n",
      "29  2016-05-30     100\n",
      "..         ...     ...\n",
      "36  2016-06-06       0\n",
      "37  2016-06-07       0\n",
      "38  2016-06-08       0\n",
      "39  2016-06-09       0\n",
      "40  2016-06-10       0\n",
      "41  2016-06-11       0\n",
      "42  2016-06-12       0\n",
      "43  2016-06-13       0\n",
      "44  2016-06-14       0\n",
      "45  2016-06-15       0\n",
      "46  2016-06-16      83\n",
      "47  2016-06-17       0\n",
      "48  2016-06-18       0\n",
      "49  2016-06-19       0\n",
      "50  2016-06-20       0\n",
      "51  2016-06-21       0\n",
      "52  2016-06-22       0\n",
      "53  2016-06-23       0\n",
      "54  2016-06-24       0\n",
      "55  2016-06-25       0\n",
      "56  2016-06-26       0\n",
      "57  2016-06-27       0\n",
      "58  2016-06-28       0\n",
      "59  2016-06-29       0\n",
      "60  2016-06-30       0\n",
      "61  2016-07-01       0\n",
      "62  2016-07-02       0\n",
      "63  2016-07-03       0\n",
      "64  2016-07-04       0\n",
      "65  2016-07-05       0\n",
      "\n",
      "[66 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print daily_frames[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### Copied program\n",
    "def get_buckets(start_date, end_date):\n",
    "    start_date_dt = datetime.strptime(start_date, '%Y-%m-%d')\n",
    "    end_date_dt = datetime.strptime(end_date, '%Y-%m-%d')\n",
    "\n",
    "    bucket_limits = [start_date_dt]\n",
    "    left_limit = start_date_dt\n",
    "    while left_limit <= end_date_dt:\n",
    "        new_limit = left_limit + timedelta(days=181)\n",
    "        if new_limit < end_date_dt:\n",
    "            bucket_limits.append(new_limit)\n",
    "        left_limit = new_limit\n",
    "    bucket_limits.append(end_date_dt)\n",
    "    return bucket_limits\n",
    "\n",
    "def get_data(bucket_start_date,bucket_end_date, keyword):\n",
    "    bucket_start_date_printed = datetime.strftime(bucket_start_date, '%Y-%m-%d')\n",
    "    bucket_end_date_printed = datetime.strftime(bucket_end_date, '%Y-%m-%d')\n",
    "    time_formatted = bucket_start_date_printed + '+' + bucket_end_date_printed\n",
    "\n",
    "    req = {\"comparisonItem\":[{\"keyword\":keyword, \"geo\": '', \"time\": time_formatted}], \"category\": 22,\"property\":\"\"}\n",
    "    hl = \"en-GB\"\n",
    "    tz = \"-120\"\n",
    "\n",
    "    explore_URL = 'https://trends.google.com/trends/api/explore?hl={0}&tz={1}&req={2}'.format(hl,tz,json.dumps(req).replace(' ','').replace('+',' '))\n",
    "    return requests.get(explore_URL).text\n",
    "\n",
    "def get_token(response_text):\n",
    "    try:\n",
    "        return response_text.split('token\":\"')[1].split('\",\"')[0]\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_csv_request(response_text):\n",
    "    try:\n",
    "        return response_text.split('\"widgets\":')[1].split(',\"lineAnno')[0].split('\"request\":')[1]       \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def get_csv(response_text):\n",
    "    request = get_csv_request(response_text)\n",
    "    token = get_token(response_text)\n",
    "\n",
    "    csv = requests.get('https://www.google.com/trends/api/widgetdata/multiline/csv?req={0}&token={1}&tz=-120'.format(request,token))\n",
    "    return csv.text.encode('utf8')\n",
    "\n",
    "def parse_csv(csv_contents):\n",
    "    lines = csv_contents.split('\\n')\n",
    "    df = pd.DataFrame(columns = ['date','value'])\n",
    "    dates = []\n",
    "    values = []\n",
    "    # Delete top 3 lines\n",
    "    for line in lines[3:-1]:\n",
    "        try:\n",
    "            dates.append(line.split(',')[0].replace(' ',''))\n",
    "            values.append(line.split(',')[1].replace(' ',''))\n",
    "        except:\n",
    "            pass\n",
    "    df['date'] = dates\n",
    "    df['value'] = values\n",
    "    return df   \n",
    "\n",
    "def get_daily_frames(start_date, end_date, keyword):\n",
    "\n",
    "    bucket_list = get_buckets(start_date, end_date)\n",
    "    frames = []\n",
    "    for i in range(0,len(bucket_list) - 1):\n",
    "        resp_text = get_data(bucket_list[i], bucket_list[i+1], keyword)\n",
    "        frames.append(parse_csv(get_csv(resp_text)))\n",
    "\n",
    "    return frames\n",
    "\n",
    "def get_weekly_frame(start_date, end_date, keyword):\n",
    "\n",
    "    if datetime.strptime(start_date, '%Y-%m-%d') > datetime.strptime(end_date, '%Y-%m-%d') - timedelta(days=180):\n",
    "        print 'No need to stitch; your time interval is short enough. '\n",
    "        return None\n",
    "    else:\n",
    "        resp_text = get_data(datetime.strptime(start_date, '%Y-%m-%d'), datetime.strptime(end_date, '%Y-%m-%d'), keyword)\n",
    "        return parse_csv(get_csv(resp_text))\n",
    "\n",
    "def get_weekly_frame2 (start_date, end_date, keyword):\n",
    "    resp_text = get_data(datetime.strptime(start_date, '%Y-%m-%d'), datetime.strptime(end_date, '%Y-%m-%d'), keyword)\n",
    "    return parse_csv(get_csv(resp_text))\n",
    "\n",
    "def stitch_frames(keywords, daily_frames, weekly_frame):\n",
    "    if weekly_frame is None:\n",
    "        return pd.concat(daily_frames, ignore_index = True)\n",
    "    else: \n",
    "        daily_frame = pd.concat(daily_frames, ignore_index = True)\n",
    "        daily_frame.columns = ['Date', 'Daily_Volume']\n",
    "        pd.to_datetime(daily_frame['Date']) \n",
    "    \n",
    "        weekly_frame.columns = ['Week_Start_Date', 'Weekly_Volume']\n",
    "        weekly_frame.index = weekly_frame['Week_Start_Date']\n",
    "        \n",
    "        daily_frame.index = daily_frame['Date']\n",
    "    \n",
    "        bins = []\n",
    "\n",
    "        for i in range(0,len(weekly_frame)):\n",
    "            bins.append(pd.date_range(weekly_frame['Week_Start_Date'][i],periods=7,freq='d'))\n",
    "\n",
    "        final_data = {}\n",
    "\n",
    "        for i in range(0,len(bins)):\n",
    "            week_start_date = datetime.strftime(bins[i][0],'%Y-%m-%d')\n",
    "            for j in range(0,len(bins[i])):\n",
    "                this_date = datetime.strftime(bins[i][j],'%Y-%m-%d')\n",
    "                try:\n",
    "                    this_val = int(float(weekly_frame['Weekly_Volume'][week_start_date])*float(daily_frame['Daily_Volume'][this_date])/float(daily_frame['Daily_Volume'][week_start_date]))\n",
    "                    final_data[this_date] = this_val\n",
    "                except:\n",
    "                    pass\n",
    "        final_data_frame = DataFrame.from_dict(final_data,orient='index').sort()\n",
    "        final_data_frame[0] = np.round(final_data_frame[0]/final_data_frame[0].max()*100,2)\n",
    "\n",
    "        final_data_frame.columns=['v_'+keywords]\n",
    "        final_data_frame.index.names = ['Date']\n",
    "\n",
    "        return final_data_frame\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fashion+week'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"fashion week\"\n",
    "s.replace(' ','+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Main function\n",
    "def get_interest_over_time (start_date, end_date, kw_list): \n",
    "    geo = ''\n",
    "    category = 22\n",
    "    final_frame = pd.DataFrame()\n",
    "    for keyword in kw_list:\n",
    "        keywords = keyword.replace(' ','+')\n",
    "        weekly_frame = get_weekly_frame2(start_date, end_date, keywords)\n",
    "        final_frame = pd.concat([final_frame, weekly_frame], axis = 1)\n",
    "    final_frame.index = final_frame.iloc[:,0]\n",
    "    final_frame = final_frame.drop('date',1)\n",
    "    final_frame.columns = kw_list\n",
    "    return final_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-a3b1e2f85b78>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-a3b1e2f85b78>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    event_term = event_term_df['Keyword'].unique().tolist().\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "## Time frame\n",
    "start_date = '2012-01-01'\n",
    "end_date = '2016-01-01'\n",
    "## Event terms\n",
    "event_term_df = pd.read_csv(\"event.csv\")\n",
    "event_term = event_term_df['Keyword'].unique().tolist()\n",
    "\n",
    "## Output csv file with events populuarity index\n",
    "#event_search_df = get_interest_over_time(start_date, end_date, event_term)\n",
    "#print event_search_df\n",
    "#event_search_df = event_search_df.to_csv('event-search.csv')\n",
    "\n",
    "print event_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Categories\n",
    "category_term_df = pd.read_csv(\"categories.csv\")\n",
    "category_term = category_term_df['Category'].tolist()\n",
    "\n",
    "#cateogry_search_df = get_interest_over_time(start_date, end_date, category_term[0])\n",
    "#print(category_search_df[:100,:7])\n",
    "#category_search_df = category_search_df.to_csv('category-search.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Category                     Event      Link           Month\n",
      "0     A-line        paris fashion week  0.000000      April-2012\n",
      "1     A-line        paris fashion week  0.000000      April-2013\n",
      "2     A-line        paris fashion week  0.536056      April-2014\n",
      "3     A-line        paris fashion week  0.000000      April-2015\n",
      "4     A-line        paris fashion week  0.000000     August-2012\n",
      "5     A-line        paris fashion week  0.000000     August-2013\n",
      "6     A-line        paris fashion week  0.000000     August-2014\n",
      "7     A-line        paris fashion week -0.801784     August-2015\n",
      "8     A-line        paris fashion week  0.000000   December-2012\n",
      "9     A-line        paris fashion week  0.000000   December-2013\n",
      "10    A-line        paris fashion week  0.000000   December-2014\n",
      "11    A-line        paris fashion week  0.000000   December-2015\n",
      "12    A-line        paris fashion week  0.000000   February-2012\n",
      "13    A-line        paris fashion week  0.000000   February-2013\n",
      "14    A-line        paris fashion week  0.000000   February-2014\n",
      "15    A-line        paris fashion week  0.792118   February-2015\n",
      "16    A-line        paris fashion week -0.636926    January-2012\n",
      "17    A-line        paris fashion week  0.000000    January-2013\n",
      "18    A-line        paris fashion week  0.000000    January-2014\n",
      "19    A-line        paris fashion week  0.000000    January-2015\n",
      "20    A-line        paris fashion week  0.000000       July-2012\n",
      "21    A-line        paris fashion week  0.000000       July-2013\n",
      "22    A-line        paris fashion week  0.000000       July-2014\n",
      "23    A-line        paris fashion week  0.000000       July-2015\n",
      "24    A-line        paris fashion week  0.000000       June-2012\n",
      "25    A-line        paris fashion week  0.000000       June-2013\n",
      "26    A-line        paris fashion week  0.000000       June-2014\n",
      "27    A-line        paris fashion week  0.000000       June-2015\n",
      "28    A-line        paris fashion week  0.000000      March-2012\n",
      "29    A-line        paris fashion week  0.084382      March-2013\n",
      "..       ...                       ...       ...             ...\n",
      "738   A-line  bread and butter fashion  0.000000    January-2014\n",
      "739   A-line  bread and butter fashion  0.000000    January-2015\n",
      "740   A-line  bread and butter fashion  0.000000       July-2012\n",
      "741   A-line  bread and butter fashion  0.000000       July-2013\n",
      "742   A-line  bread and butter fashion  0.000000       July-2014\n",
      "743   A-line  bread and butter fashion  0.000000       July-2015\n",
      "744   A-line  bread and butter fashion  0.000000       June-2012\n",
      "745   A-line  bread and butter fashion  0.000000       June-2013\n",
      "746   A-line  bread and butter fashion  0.000000       June-2014\n",
      "747   A-line  bread and butter fashion  0.000000       June-2015\n",
      "748   A-line  bread and butter fashion  0.000000      March-2012\n",
      "749   A-line  bread and butter fashion  0.084382      March-2013\n",
      "750   A-line  bread and butter fashion  0.000000      March-2014\n",
      "751   A-line  bread and butter fashion -0.476731      March-2015\n",
      "752   A-line  bread and butter fashion  0.000000        May-2012\n",
      "753   A-line  bread and butter fashion  0.000000        May-2013\n",
      "754   A-line  bread and butter fashion  0.000000        May-2014\n",
      "755   A-line  bread and butter fashion  0.000000        May-2015\n",
      "756   A-line  bread and butter fashion  0.000000   November-2012\n",
      "757   A-line  bread and butter fashion  0.000000   November-2013\n",
      "758   A-line  bread and butter fashion  0.000000   November-2014\n",
      "759   A-line  bread and butter fashion  0.000000   November-2015\n",
      "760   A-line  bread and butter fashion  0.000000    October-2012\n",
      "761   A-line  bread and butter fashion  0.000000    October-2013\n",
      "762   A-line  bread and butter fashion  0.000000    October-2014\n",
      "763   A-line  bread and butter fashion  0.000000    October-2015\n",
      "764   A-line  bread and butter fashion  0.000000  September-2012\n",
      "765   A-line  bread and butter fashion  0.000000  September-2013\n",
      "766   A-line  bread and butter fashion  0.000000  September-2014\n",
      "767   A-line  bread and butter fashion  0.000000  September-2015\n",
      "\n",
      "[768 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "### Calculate the correlation\n",
    "event_search_df = pd.read_csv(\"event-search.csv\")\n",
    "category_search_df = pd.read_csv(\"category-search-manual.csv\")\n",
    "event_term_list = event_search_df.columns[1:]\n",
    "category_term_list = category_search_df.columns[1:]\n",
    "\n",
    "event_search_df['date'] = pd.to_datetime(event_search_df['date'])\n",
    "category_search_df['date'] = pd.to_datetime(category_search_df['date'])\n",
    "event_search_df['Month'] = event_search_df['date'].apply(lambda x: x.strftime('%B-%Y'))\n",
    "#category_search_df['Week'] = category_search_df['date'].apply(lambda x: x.strftime('%B-%Y'))\n",
    "\n",
    "\n",
    "edge_list = pd.DataFrame(columns = ['Month','Category', 'Event', 'Link'])\n",
    "concat_df = pd.concat([event_search_df, category_search_df], axis = 1)\n",
    "\n",
    "for category in category_term_list:\n",
    "    for event in event_term_list:\n",
    "        temp = concat_df.groupby('Month')[[category, event]].corr().ix[0::2,event]\n",
    "        temp = temp.reset_index()\n",
    "        temp.columns = ['Month', 'Category','Link']\n",
    "        temp['Event'] = event\n",
    "        edge_list = edge_list.append(temp, ignore_index = True)\n",
    "\n",
    "edge_list = edge_list.fillna(0)\n",
    "\n",
    "print edge_list\n",
    "edge_list.to_csv(\"edge-list.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
